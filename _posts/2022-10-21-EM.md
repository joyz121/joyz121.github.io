---
layout: post
title: "机器学习：（二）EM算法"
subtitle: "EM算法推导"
author: "Joy"
header-img: "img/post-bg-rwd.jpg"
header-mask: 0.2
tags:
  - 机器学习
---

对于给定数据集，通过对模型的假设，然后用极大似然估计估计模型参数。但是在一些情况下，得到的观察数据有未观察到的隐含数据，此时我们未知的有隐含数据和模型参数，因而无法直接用极大似然估计得到模型分布的参数。怎么办呢？
这时可以通过EM算法求解。EM算法解决这个的思路是使用启发式的迭代方法，既然无法直接求出模型分布参数，那么可以先猜想隐含数据（EM算法的E步），接着基于观察数据和猜测的隐含数据一起来极大化对数似然，求解我们的模型参数（EM算法的M步)。由于我们之前的隐藏数据是猜测的，所以此时得到的模型参数一般还不是我们想要的结果。不过没关系，我们基于当前得到的模型参数，继续猜测隐含数据（EM算法的E步），然后继续极大化对数似然，求解我们的模型参数（EM算法的M步)。以此类推，不断的迭代下去，直到模型分布参数基本无变化，算法收敛，找到合适的模型参数。

## EM算法导出

极大化似然函数：

 $$\theta^*=\arg\max_\theta P(X\mid \theta)$$

然后加入隐变量$Z$，可以将似然函数改写为：

$$P(X\mid\theta)=\sum_{Z}P(Z,X\mid\theta)
=\sum_{Z}P(Z\mid\theta)P(X\mid Z, \theta)$$

对数似然函数为：

$$L(\theta,X)=logP(X\mid\theta)=log(\sum_{Z}P(Z\mid\theta)P(X\mid Z,\theta))$$

如果直接对参数求偏导然后令其为0，求解将会十分困难。EM的求解思想是寻找一个参数序列，使得对数似然函数逐步提升：

$$\log P(X\mid \theta^{(t)}) \leq \log P(X\mid \theta^{(t+1)})$$
首先将对数似然函数改写为：

$$\begin{aligned}
\log P(X\mid\theta)&=log (\frac{P(X,Z\mid\theta)}{P(Z\mid X,\theta)})\\
\log P(X\mid\theta)&=\log P(X,Z\mid\theta)-\log P(Z\mid X,\theta)\\
\log P(X\mid\theta)&=\log \frac{P(X,Z\mid\theta)}{q(Z)}-\log \frac{P(Z\mid X,\theta)}{q(Z)}\\
\sum\limits_{Z}q(Z) \log P(X\mid\theta)&=\sum\limits_{Z}q(Z) \log \frac{P(X,Z\mid\theta)}{q(Z)}-\sum\limits_{Z}q(Z)\log \frac{P(Z\mid X,\theta)}{q(Z)}\\
\log P(X\mid\theta)&=\sum\limits_{Z}q(Z) \log \frac{P(X,Z\mid\theta)}{q(Z)}-\sum\limits_{Z}q(Z)\log \frac{P(Z\mid X,\theta)}{q(Z)}\end{aligned}$$

将$\sum\limits_{Z}q(Z) \log \frac{P(X,Z\mid\theta)}{q(Z)}$称作ELBO(evidence lower bound)，$(-\sum\limits_{Z}q(Z)\log \frac{P(Z\mid X,\theta)}{q(Z)})$为前面介绍的KL散度，记为：$KL(q(z)||P(Z\mid X,\theta))$，因此，对数似然函数可以写为：

$$\begin{aligned}
  \log P(X\mid\theta)&=ELBO+ KL(q(z)||P(Z\mid X,\theta))\\
  &\geq ELBO\end{aligned}$$

当$q(Z)=P(Z\mid X,\theta)$时，等号成立，于是：

 $$\begin{aligned}
    \theta^*&=\arg\max_\theta P(X\mid \theta)\\
    &=\arg\max_\theta ELBO\\
    &=\arg\max_\theta \sum\limits_{Z}q(Z) \log \frac{P(X,Z\mid\theta)}{q(Z)}\\
    &=\arg\max_\theta \sum\limits_{Z}P(Z\mid X,\theta^{t}) \log \frac{P(X,Z\mid\theta)}{P(Z\mid X,\theta^{t})}\\
    &=\arg\max_\theta \sum\limits_{Z}P(Z\mid X,\theta^{t})\log P(X,Z\mid\theta)\end{aligned}$$

##收敛性

首先求$L(\theta)$在分布$P(Z\mid X,\theta^t)$上的期望：

 $$\begin{aligned}
\sum_{Z}\log P(X\mid\theta)P(Z\mid X,\theta^t)&=\sum_{Z}\log P(X,Z\mid\theta)P(Z\mid X,\theta^t)-\sum_{Z}\log P(Z\mid X,\theta)P(Z\mid X,\theta^t)\\
\Rightarrow \log P(X\mid\theta)&=\sum_{Z}\log P(X,Z\mid\theta)P(Z\mid X,\theta^t)-\sum_{Z}\log P(Z\mid X,\theta)P(Z\mid X,\theta^t)\\
\Rightarrow L(\theta)&=Q(\theta,\theta^t)-H(\theta,\theta^t)\end{aligned}$$

因为$\theta^{t+1}=\arg\max_\theta Q(\theta,\theta^t)$，必然有$Q(\theta^{t+1},\theta^t)\geq Q(\theta^t,\theta^t)$，接下来证明$H(\theta^{t+1},\theta^t)\leq H(\theta^t,\theta^t)$：

$$\begin{aligned}
    H(\theta^{t+1},\theta^t)-H(\theta^t,\theta^t)&=\sum_{Z}\log P(Z\mid X,\theta^{t+1})P(Z\mid X,\theta^t)-\sum_{Z}\log P(Z\mid X,\theta^t)P(Z\mid X,\theta^t)\\
    &=\sum_{Z}(\log\frac{P(Z\mid X,\theta^{t+1})}{P(Z\mid X,\theta^t)})P(Z\mid X,\theta^t)\\
    &=-KL(P(Z\mid \theta^t)||P(Z\mid X,\theta^{t+1}))\\
    &\leq 0\end{aligned}$$

所以，$L(\theta^{t+1}) \geq L(\theta^t)$，似然函数收敛。

## 算法步骤

- E-step：计算$\sum\limits_{Z}P(Z\mid X,\theta^{t})\log P(X,Z\mid\theta)$。

- M-step:
  根据$\theta^{t+1}=\arg\max \sum\limits_{Z}P(Z\mid X,\theta^{t})\log P(X,Z\mid\theta)$更新参数。

后续将在HMM、GMM等模型中应用EM算法。