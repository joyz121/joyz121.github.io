---
layout: post
title: "机器学习：（一）数学基础"
subtitle: "概率基础"
author: "Joy"
header-img: "img/post-bg-rwd.jpg"
header-mask: 0.2
tags:
  - 机器学习
---

## 一维高斯分布

一维高斯分布概率密度函数(PDF)：
$$p(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{(x-\mu)^2}{2\sigma^2})$$

## 多维高斯分布

多维高斯分布概率密度函数：

$$p(x)=\frac{1}{(2\pi)^{(\frac{p}{2})}(\Sigma)^\frac{1}{2}}\exp(-\frac{1}{2}(x-\mu)^T \Sigma^{-1}(x-\mu))$$

其中 $x,\mu\in\mathbb{R}^{p},\Sigma\in\mathbb{R}^{p\times p}$ ，$\Sigma$为协方差矩阵，一般是半正定矩阵。这里假设它是正定的。首先我们处理指数上的数字，指数上的数字可以记为$x$ 和 $\mu$之间的马氏距离。对于对称的协方差矩阵可进行特征值分解：

$\Sigma=U\Lambda U^{T}=(u_{1},u_{2},\cdots,u_{p})diag(\lambda_{i})(u_{1},u_{2},\cdots,u_{p})^{T}=\sum\limits _{i=1}^{p}u_{i}\lambda_{i}u_{i}^{T}$

于是：
$$\Sigma^{-1}=\sum\limits _{i=1}^{p}u_{i}\frac{1}{\lambda_{i}}u_{i}^{T}$$
$$\Delta=(x-\mu)^{T}\Sigma^{-1}(x-\mu)=\sum\limits _{i=1}^{p}(x-\mu)^{T}u_{i}\frac{1}{\lambda_{i}}u_{i}^{T}(x-\mu)$$
令$y_i=(x-\mu)^Tu_i$,得$\Delta=\sum\limits _{i=1}^{p}\frac{y_{i}^{2}}{\lambda_{i}}$，将$y_{i}$看做 $x-\mu$ 在特征向量 $u_{i}$ 上的投影，当$p=2$时，上式就是 $\Delta$
取不同值时的同心椭圆,如图

![gaussian_example](/img/in-post/gaussian_example.png)